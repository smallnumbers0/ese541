{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "In the coding project below, answer relevant questions on Canvas via the assigment named Programming Project 3 Quiz Questions.\n",
    "\n",
    "In the following exercise, we will perform linear regression to fit various data sets and to predict outputs. Perform the following analyses by starting a new notebook. \n",
    "\n",
    "In this assignment, we will be using PennGrader, a Python package built by a former TA for autograding Python notebooks. PennGrader was developed to provide students with instant feedback on their answer. You can submit your answer and know whether it's right or wrong instantly. We then record your most recent answer in our backend database. You will have 100 attempts per test case, which should be more than sufficient.\n",
    "\n",
    "<b>NOTE：Please remember to remove the </b>\n",
    "\n",
    "```python\n",
    "raise notImplementedError\n",
    "```\n",
    "<b>after your implementation, otherwise the cell will not compile.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Setup\n",
    "Please run the below cells to get setup with the autograder. If you need to install packages, please uncomment and try the following lines; if they do not work, please try running them in the terminal without the `!` sign! (e.g. `pip install sklearn --user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install penngrader --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn --user\n",
    "# !pip install sklearn --user\n",
    "# !pip install statsmodels --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try PennGrader out! Fill in the cell below with your PennID and then run the following cell to initialize the grader.\n",
    "\n",
    "<font color='red'>Warning:</font> Please make sure you only have one copy of the student notebook in your directory in Codio upon submission. The autograder looks for the variable `STUDENT_ID` across all notebooks, so if there is a duplicate notebook, it will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLEASE ENSURE YOUR STUDENT_ID IS ENTERED AS AN INT (NOT A STRING). IF NOT, THE AUTOGRADER WON'T KNOW WHO \n",
    "#TO ASSIGN POINTS TO YOU IN OUR BACKEND\n",
    "\n",
    "STUDENT_ID = 56803282                   # YOUR 8-DIGIT PENNID GOES HERE\n",
    "STUDENT_NAME = \"Jacky Choi\"     # YOUR FULL NAME GOES HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import penngrader.grader\n",
    "\n",
    "grader = penngrader.grader.PennGrader(homework_id = 'ESE542_Online_Su_2021_HW3', student_id = STUDENT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the relevant Python packages here\n",
    "# Feel free to import any other packages for this project\n",
    "\n",
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# ML\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Statistics\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "blue = '#008FD5'\n",
    "red = '#FF2700'\n",
    "green = '#77AB43'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very important (read: **the most important** topic) in practical data science scenarios is that of data leakage. Data leakage is a situation that occurs when the creator of a machine learning model allows the model to read both training data and test data to train the model. In Programming Project 3, the training data and the test data are separated for you already. Thus, the linear regression model should only be trained with the training data. Predictions can be made on either the training data or the test data. In the upcoming weeks, we will explore why you shouldn't train the model with the test data as well and what methods we can employ to choose the training set and the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "First, we will use the `Ch3PartA` dataset to generate polynomial regressions using `scikit-learn`.\n",
    "This dataset contains 100 observations of points $x$ and their corresponding response, $y$. The data\n",
    "is divided into a training set $(x_{tr}, y_{tr})$ and a test set $(x_{te}, y_{te})$, and all the values are doubles.\n",
    "\n",
    "### A1.\n",
    "\n",
    "To start, load `Ch3PartA.csv` into your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_tr</th>\n",
       "      <th>y_tr</th>\n",
       "      <th>x_te</th>\n",
       "      <th>y_te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.249973</td>\n",
       "      <td>-0.225565</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>0.043946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073364</td>\n",
       "      <td>0.435610</td>\n",
       "      <td>0.483860</td>\n",
       "      <td>-0.066113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.663146</td>\n",
       "      <td>0.507205</td>\n",
       "      <td>0.123247</td>\n",
       "      <td>0.859564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595366</td>\n",
       "      <td>0.059467</td>\n",
       "      <td>0.307679</td>\n",
       "      <td>-0.305032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.415146</td>\n",
       "      <td>-0.035114</td>\n",
       "      <td>0.926060</td>\n",
       "      <td>-0.472700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.320401</td>\n",
       "      <td>-0.488202</td>\n",
       "      <td>0.897397</td>\n",
       "      <td>-0.735587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.164287</td>\n",
       "      <td>0.251095</td>\n",
       "      <td>0.119381</td>\n",
       "      <td>0.865596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.783161</td>\n",
       "      <td>-0.291251</td>\n",
       "      <td>0.327843</td>\n",
       "      <td>-0.391891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.122498</td>\n",
       "      <td>0.403176</td>\n",
       "      <td>0.815745</td>\n",
       "      <td>-0.400014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.634907</td>\n",
       "      <td>0.523561</td>\n",
       "      <td>0.597312</td>\n",
       "      <td>-0.027795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_tr      y_tr      x_te      y_te\n",
       "0   0.249973 -0.225565  0.006047  0.043946\n",
       "1   0.073364  0.435610  0.483860 -0.066113\n",
       "2   0.663146  0.507205  0.123247  0.859564\n",
       "3   0.595366  0.059467  0.307679 -0.305032\n",
       "4   0.415146 -0.035114  0.926060 -0.472700\n",
       "..       ...       ...       ...       ...\n",
       "95  0.320401 -0.488202  0.897397 -0.735587\n",
       "96  0.164287  0.251095  0.119381  0.865596\n",
       "97  0.783161 -0.291251  0.327843 -0.391891\n",
       "98  0.122498  0.403176  0.815745 -0.400014\n",
       "99  0.634907  0.523561  0.597312 -0.027795\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Ch3PartA.csv\")\n",
    "data2 = data.copy() #just for fun\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2.\n",
    "\n",
    "Create a scatter plot of: \n",
    "\n",
    "(a) `y_tr` against `x_tr` and another of \n",
    "\n",
    "(b) `y_te` against `x_te`. \n",
    "\n",
    "\n",
    "Then, observe and comment on the similarities and differences between the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>x_tr</td>       <th>  R-squared (uncentered):</th>      <td>   0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   13.12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Sep 2024</td> <th>  Prob (F-statistic):</th>          <td>0.000463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:10:45</td>     <th>  Log-Likelihood:    </th>          <td> -75.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th>          <td>   152.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    99</td>      <th>  BIC:               </th>          <td>   154.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>y_tr</th> <td>   -0.4524</td> <td>    0.125</td> <td>   -3.622</td> <td> 0.000</td> <td>   -0.700</td> <td>   -0.205</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.046</td> <th>  Durbin-Watson:     </th> <td>   0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.132</td> <th>  Jarque-Bera (JB):  </th> <td>   3.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.391</td> <th>  Prob(JB):          </th> <td>   0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.481</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                   x_tr   R-squared (uncentered):                   0.117\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.108\n",
       "Method:                 Least Squares   F-statistic:                              13.12\n",
       "Date:                Sat, 21 Sep 2024   Prob (F-statistic):                    0.000463\n",
       "Time:                        17:10:45   Log-Likelihood:                         -75.154\n",
       "No. Observations:                 100   AIC:                                      152.3\n",
       "Df Residuals:                      99   BIC:                                      154.9\n",
       "Df Model:                           1                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "y_tr          -0.4524      0.125     -3.622      0.000      -0.700      -0.205\n",
       "==============================================================================\n",
       "Omnibus:                        4.046   Durbin-Watson:                   0.443\n",
       "Prob(Omnibus):                  0.132   Jarque-Bera (JB):                3.664\n",
       "Skew:                           0.391   Prob(JB):                        0.160\n",
       "Kurtosis:                       2.481   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAH3dJREFUeJzt3X/wXHV97/Hni2BIM7ZNSFJu+JEERyqgvYD5FnWcqYKoyEwInTo2TNRo7c3U1taL93INN9OhF5pKdXqpnVExl6JRckXqvdZv7tXhIqDOOMbhi/KbUmIUSIglgjDjRJSE9/3jnK/ZXfbsnt1z9uw5u6/HzM7unvPZ3c/5fnfP+/P7KCIwMzObd8y4M2BmZvXiwGBmZm0cGMzMrI0Dg5mZtXFgMDOzNg4MZmbWxoHBzMzaODCYmVkbBwYzM2tz7LgzMIzly5fHmjVrxp0NM7NGueuuu34SESv6pWtkYFizZg1zc3PjzoaZWaNIejRPulKakiTdIOlJSfdn7Jekf5C0R9K9kl7dsm+TpEfS26Yy8mNmZsMrq4/hs8CFPfa/DTgtvW0GPgUg6XjgSuA1wLnAlZKWlpQnMzMbQimBISK+BTzdI8l64HOR2A0skbQSeCtwa0Q8HRE/BW6ld4AxM7MRq2pU0knA4y3P96Xbsra/iKTNkuYkzR08eHBkGTUzm3aNGa4aEdsjYiYiZlas6NupbmZmQ6oqMOwHTml5fnK6LWv75Nq1E85fA2cck9zv2jnuHJmZtakqMMwC705HJ70WeDYiDgC3AG+RtDTtdH5Lum0y7doJf7kZnngUIpL7v9zs4GBmtVLKPAZJXwDeCCyXtI9kpNFLACLiOuCrwEXAHuAQ8N5039OSrgbuTN/qqojo1YndbNduhecOtW977lCyfd3G8eTJzKxDKYEhIi7tsz+AP8vYdwNwQxn5qL0Djw223cxsDBrT+TwRVq4abLuZ2Rg4MFTpsm2waHH7tkWLk+1mZjXhwFCldRvh6u1w4mqQkvurt7t/wcxqpZGL6DXauo0OBGZWa64xmJlZGwcGMzNr48BgZmZtHBjMzKyNA4OZmbVxYBgnL6hnZjXkwFBEkRO7F9Qzs5pyYBhW0RN7rwX1zMzGyIFhWEVP7F5Qz8xqyoFhWEVP7F5Qz8xqyoFhWEVP7F5Qz8xqyoFhWEVP7F5Qz8xqyovoDWv+BH7t1qT5aOWqJCgMcmL3gnpmVkNlXdrzQuDjwALg+oi4pmP/tcB56dPFwG9FxJJ03xHgvnTfYxFxcRl5qoRP7GY2gQoHBkkLgE8Abwb2AXdKmo2IB+fTRMRlLen/HDin5S1+HhFnF82HmZmVo4w+hnOBPRGxNyJ+CdwErO+R/lLgCyV8rpmZjUAZgeEk4PGW5/vSbS8iaTVwKnB7y+ZFkuYk7ZZ0SQn5MTOzAqrufN4AfCkijrRsWx0R+yW9DLhd0n0R8YPOF0raDGwGWLXKY/3NzEaljBrDfuCUlucnp9u62UBHM1JE7E/v9wLfoL3/oTXd9oiYiYiZFStWFM3z8LzwnZlNuDICw53AaZJOlbSQ5OQ/25lI0unAUuA7LduWSjoufbwceD3wYOdra8ML35nZFCgcGCLiMPAB4BbgIeDmiHhA0lWSWoeebgBuioho2XYGMCfpHuAO4JrW0Uy144XvzGwKqP083QwzMzMxNzdX/QefcUxSU+gkwUMvVJ8fM7MBSLorImb6pfOSGIPwwndmNgUcGAbhhe/MbAo4MAzCC9+Z2RTwInqD8vpIZjbhXGMwM7M2DgxmZtbGgcHMzNo4MJiZWRsHBjMza+PAMGm8yJ+ZFeTAUKVRn7S9yJ+ZlcCBoSpVnLS9yJ+ZlcCBoSpVnLQPPNZ9+xOPutZgZrk5MORVtBko66SdtX0YvRbzc5OSmeXkwJBHGc1AVazM2m2Rv3luUjKznBwY8iijGaiKlVnnF/nLUmbtxMwmlgNDHmU0A1W1Muu6jcl7d+PrRpiHM1sODgx5lNUMtG4j3P6j5Gpvt/9odKu0+roR1o2HM1tOpQQGSRdKeljSHklbuux/j6SDku5Ob3/csm+TpEfS26Yy8lO6pp1ofd0I6yZvk6hrFVOvcGCQtAD4BPA24EzgUklndkn6xYg4O71dn772eOBK4DXAucCVkpYWzVPp5k+0S5Yd3bbo1+B73+7/AxrXj6yq2ok1R54mUdcqjHJqDOcCeyJib0T8ErgJWJ/ztW8Fbo2IpyPip8CtwIUl5Gk0nvv50cfPPAVf+FTvH5B/ZDZqgxQ8spo+jznm6Ou3fdCTJK2UwHAS8HjL833ptk5/IOleSV+SdMqArx2/btXwTp0/IM9EtlEatOCRNZz5yJGjr3/mqe6v9Yi2qVJV5/MuYE1E/HuSWsGOQd9A0mZJc5LmDh48WHoG+8r7w2hNV8WkNptegxY8OvueFizI/1ke0TZVyggM+4FTWp6fnG77lYh4KiJ+kT69Hlib97Ut77E9ImYiYmbFihUlZHtAeX8YremqmNRm02uYgkdr39MLL+T7nDoPtLCRKCMw3AmcJulUSQuBDcBsawJJK1ueXgw8lD6+BXiLpKVpp/Nb0m3102tW8bzOH1DTRjNZsxQteGSlW7LMI9qmXOHAEBGHgQ+QnNAfAm6OiAckXSXp4jTZX0h6QNI9wF8A70lf+zRwNUlwuRO4Kt1WP92GgF76/t4/oFENG/VwQoPiBY+s12/9uEe0TbuIaNxt7dq1URuzN0actzridCX3szeO/vPOWhzxCo7ezlo8+s+1eir6/av6+2tjBcxFjnOskrTNMjMzE3Nzc+POxtFRIa0dgIsWj7bqff6aZPRIpxNXJ6U7M7MMku6KiJl+6bwkRhFFhqMO2xzkkU5mNmIODEUMe5LuNv788nfBf/vT/p/pkU5WtWEKMe4HazQHhm7yfqmHPUl3nSwXcNN1/X9AHulkVRpm9r5n/DeeA0OnQb7Uw56ks2oUEf2bobxAnlVpmOZSz/hvPHc+dxq0c3fXzuQLf+CxpKZw2bb+J+msz4DkZP9QzolHZqN2xjFJgaVTr+/pMK+xSrjzeViD9hsMs4rpZdsAdd/nvgKrk2GaS90P1ngODJ2q+FKv2wiX/klSgmrlvgKrm2GaS90P1ngODJ2q+lJf+Un46OfdV2D1NkyflvvBGs99DN0M029gVgZ/92yE8vYxHFtFZhpn3Ub/GK16nTPp50fEgb+PVik3JU0STypqNg/ztJpwjWFSuLTZfF7uxGrCNYYsTSt9u7TZfB7maTXhwNBNE6f0u7TZfB7maTXhwNBNE0vfLm02n4d5Wk04MHTTxNJ3kdJm05rNJtkwM+nNSubA0E0TS9/Dljab2GxmZiNVSmCQdKGkhyXtkbSly/4PSXpQ0r2SbpO0umXfEUl3p7fZMvJTWJ3benuV7ocpbTax2czMRqrwcFVJC4BPAG8G9gF3SpqNiAdbkn0fmImIQ5LeD3wU+MN0388j4uyi+SjV/Am1bjNQRzEktYnNZmY2UmXUGM4F9kTE3oj4JXATsL41QUTcERHzxdLdwMklfO5o1bGtdxSl+yY2m5nZSJURGE4CHm95vi/dluV9wNdani+SNCdpt6RLSsjP5BpF6b7OzWbWHB7AMFEqnfks6Z3ADPCGls2rI2K/pJcBt0u6LyJ+0OW1m4HNAKtWTWlpduWq7hf4KVK6r2uzmTWHZ91PnDJqDPuBU1qen5xuayPpAmArcHFE/GJ+e0TsT+/3At8Azun2IRGxPSJmImJmxYoVJWS7gUZVuq9js5k1hwcwTJwyAsOdwGmSTpW0ENgAtI0uknQO8GmSoPBky/alko5LHy8HXg+0dlpbK0+AapZpaV7Jasp84tHpOP4JVLgpKSIOS/oAcAuwALghIh6QdBUwFxGzwMeAlwL/pOSqZY9FxMXAGcCnJb1AEqSu6RjNZJ28JHgzTFPzSlYTJzq6fZKPfwL5Qj3TyBeDGb3z13Q/WZ64OmmumySdQRCSGm23c8skHn+D5L1Qj2c+TxvPdK7GNM0P6dbEmVXgnMTjn0AODJOus5172wfdUViFaZsf0jmA4cTV3dNN6vFPGAeGSdatdvDMU93TuiRXrmmfHzLtx99wDgyTrNswwiwuyZVr2keQTfvxN5wDwyTLWwtwSa67osNN6zA/ZJxDZutw/DYUB4ZJllULWLLMJbl+JqGTflKOwXMhKufAMMmy2nm3ftwluX4mYTZv049hEgJbWSoOkA4Mk8ztvMObhOGmTT+Gpge2sowhQDowTDq38w5nEoabNv0Ymh7YyjKGAOnAYNbNGy5KalmtmtZJ3/Qho00PbGUZQ4B0YDDrtGsnfHlHx+xdwe9valaNq+lNiU0PbGUZQ4CcnsDg0Q2WV9f5HwHf/OpYslNIk5sSmx7YyjKGADkdgcGjG2wQTWrbnvQCT5MDW1nGECCnIzBkdd5s2TR5PyTLL+uk2pS2bRd4pkfFAXI6AkNWSe/IEf+QplWvk2pT2rY9nHPyjalGOB2BoVdJzz+k6dTrpNqUtu0mNXnZ4MZYI5yOwNCtBNjKP6TqZJWAqi4Z9Tup9qu616FtvylNXjacMdYIC1/asxHmf9RbNiXNR538Q6pG1uUuv/ftZHholZfBzLocZZ7vQl0u23nZthdfOa2OTV42nDHWCEupMUi6UNLDkvZI2tJl/3GSvpju/66kNS37rki3PyzprWXkp6t1G+GaHc1oO55UWSWgm7dXXzIq0o9QVkmujNVbm9DkZcMZY42wcGCQtAD4BPA24EzgUklndiR7H/DTiHg5cC3wt+lrzwQ2AK8ELgQ+mb7faPiHNF69BgEMkr4MRb4LZZTkymo/bvpwzjo0ydXVGAdBKLKuzZr3DaTXAX8VEW9Nn18BEBEfaUlzS5rmO5KOBX4MrAC2tKZtTdfrM2dmZmJubq5Qvm0Mzl/TvflmwYLuwaGuF47POo5B8lvGezRdZ5McJCc+F9aO2rUzqYkeeCypKVy2rdDfRtJdETHTL10ZTUknAY+3PN+XbuuaJiIOA88Cy3K+FgBJmyXNSZo7ePBgCdm2ymWVgN6xuVlNfGWU5DyiyMNt8xhTjbAxo5IiYntEzETEzIoVK8adHRtGVvPNlZ8cbRNf2c0VeZuhen2uRxQ5OOYxrqa2iCh0A14H3NLy/Argio40twCvSx8fC/wEUGfa1nS9bmvXro1CZm+MOG91xOlK7mdvLPZ+k6QJf5tB8jh7Y8RZiyNewdHbWYtHf1z9Pndc+aqT81a3H//87bzV485ZPYzgOwLMRZ7zep5EPd8gOdHvBU4FFgL3AK/sSPNnwHXp4w3AzenjV6bpj0tfvxdY0O8zCwUG/yCzNeFvM2gex3XyyfO5TQjCo9SE79s4ZX2HXrNs6LfMGxgKdz4DSLoI+HtgAXBDRGyTdFWaiVlJi4DPA+cATwMbImJv+tqtwB8Bh4H/GBFf6/d5hTqf3emXrQl/m0HzeMYxHctnp6Sk3XZUTlf37aP+3KYpuXN1omR9dwE+duNQf6e8nc+lBIaqFQoM4zpRNEET/jaD5nEcwW7XTvgv7+qezzoFWau3rO8uDP09qnJUUrO40y9bHf42/TrbBs3jOMaCX7s1o6Sn+o60qpLnLuTT67sy4g766QsMTVk5cxyy1pQ69LPhf7yDnATyTPoa9P83jkmNmT/acDOJlwrPb91GWLKs+74RF9amLzB49nO2+b9N55fxmaeG+/EOehLIM6496/8H2QGo6rHgWT/aE1eP9nObwHMXBrP142MpyE5fH4O92K6dsO2DSQAA0DEQXdrrB23XrKqjuG4zaOuWnzppQj9W3ZTYQe8+Bstn10644r1HgwJ0DwoweLvmoBOYhu3jqFsp1LXSbHXox2qaMcx+dmCYdtduhcPP50s76I+3qo7iOs6gbfridqPiPr5GcGCYdnlPnsP8ePudBDo7pmG4krZLoc3h2lQjTMeFeixb1gVrIFn19IUXhm/XnE/frX0062I3V28ffHy2L1jTLOs2OhDUnDufp918H0Nnc9JLFsLf3DC6H3DZE888g9asL3c+Wz7rNsJHPtM+RHXJstEGBSi/X2DQNn1PsjLL5KYkG0/Vvsg1l4uqyzWbzWrKNQYbj3GMTpmvJVz+znoNbzWrGdcYbDx6dUyPQrdJZ518gRgzYJpqDG5Trp8qx/p3mwTXycNbzYBpqTG4Tdn61QY8vNXsV6ajxlC3JROaYNJqWL1qA55kZdZmOgJDHZdMqLNJXBo5q7P7YzcenTcxSYHQrIBCgUHS8ZJulfRIer+0S5qzJX1H0gOS7pX0hy37Pivph5LuTm9nF8lPJi+ZMJhJrGH1WophEgOhWQFFawxbgNsi4jTgtvR5p0PAuyPilcCFwN9LWtKy//KIODu93V0wP9154a7BFK1h1bUZKquzexIDoVkBRQPDemBH+ngHcElngoj414h4JH38BPAksKLg5w7GC3cNpkgNq4mlbzc1mrUpGhhOiIgD6eMfAyf0SizpXGAh8IOWzdvSJqZrJR1XMD/ZvAxyfkVqWE0sfbup0axN38Ag6euS7u9yW9+aLpLV+DJX5JO0Evg88N6IX10J5grgdOB3geOBD/d4/WZJc5LmDh482P/IbHhFalhNLH27qXG86tr0OM0iYugb8DCwMn28Eng4I91vAN8D3t7jvd4I/J88n7t27dqwmjpvdcQrePHtvNXjzdfsjUkeTldyP3vjYPttNGZvjDhrcft35azF7X9//29KA8xFjnNs0aakWWBT+ngT8JXOBJIWAl8GPhcRX+rYtzK9F0n/xP0F82PjVsfSd55+Dzc1jke/pscm9llNgKKB4RrgzZIeAS5InyNpRtL1aZp3AL8HvKfLsNSdku4D7gOWA39dMD82bnXs6B91v4ebQobXr+mxiX1WE8AX6rHJd8YxSWmzk5TUEIrotjjfosXjD4ZN0e+CTaP8300hX6jHyjGO0nDZnznKUUcu0RbTr+nRI8bGwoHBsg3bvlvkxD6KNuVR9ns0cRRWnfRreizyv3MT39DclGTZhrkuc9GmlbKvBd2ar1Fc+2FU+bWjhvnfuYmvq7xNSQ4Mlm3Q9t1dO2HLJjhy5MX78p4om9am7BNQPTlgd+U+BitukPbd+RNkt6AA+ZtWmtamXMdRWOYmvoIcGCzbIO27/a6QlvfEXsd5EP14DkT9NK2A0U/F/SUODJZtkNJwr5JYvxN765f+2q3w+5tcArdimljAyDKGSX7uY7ByZLXpLlgA1+zIPrG7jd5GZVQDDqpWYn+JO5+tWsOe4IcNKGbTosQBGe58tmoN2wmb1QR15IjXxDGDsfSXODBYeYbphO315fZ6RmZj6S9xYLDx6valb1XG8EKv0GlNNoYh0Q4MNl7zX/oFC7rv93pGBq7xVTwk+tiRvrtZHvNf8m6d117PyDoHNszX+MCDE0bENQarh1FWlydtstO0cY2vcq4xWH2s21hOIOgcv7765d2HxL7houKfZaPnGl/lHBhssnRrdngi4wTyza9Wly8b3spV3QO7a3wj46Ykq9aoOxG7rtmUMYnTJc5mmKTlLRqiUGCQdLykWyU9kt4vzUh3pOV6z7Mt20+V9F1JeyR9UdLCIvmxmqti2OggJ3uXOJvBK9hWrtCSGJI+CjwdEddI2gIsjYgPd0n3s4h4aZftNwP/OyJuknQdcE9EfKrf53pJjIaqYo38rM+Q2pcV8HpMNoWqWhJjPbAjfbwDuCTvCyUJOB/40jCvtwaqohMxq9lhw5+4xDlpymqWnPY5El0U7Xw+ISIOpI9/DJyQkW6RpDngMHBNRPwzsAx4JiIOp2n2AScVzI/VWRWdiPMn+0lYVdOylTW3wXMkuurblCTp68C/67JrK7AjIpa0pP1pRLyon0HSSRGxX9LLgNuBNwHPArsj4uVpmlOAr0XEqzLysRnYDLBq1aq1jz7a5QRj9eYltq0sWU2GS5Yl9888dfT51o9nf7+m7BKgeZuS+tYYIuKCHh/yb5JWRsQBSSuBJzPeY396v1fSN4BzgP8FLJF0bFprOBnY3yMf24HtkPQx9Mu31ZBL81aWrObH+YDQ+vyK9yaPB7nA1JSPWCvaxzALbEofbwK+0plA0lJJx6WPlwOvBx6MpKpyB/D2Xq+3CVPGmi9uE7ZBmh8PP589S9qz4rsqGhiuAd4s6RHggvQ5kmYkXZ+mOQOYk3QPSSC4JiIeTPd9GPiQpD0kfQ7/WDA/Num8UqpB/1V5O2XVADxHoitfwc2aZcrahK2HzqVPDv3sxU1J83p9PyblEqA5+NKeNplKvMyhTZhdO+G//hE8/8v27ce+BD7ymYk92Q/Cl/a0yeQ2YcuybiP8zQ1HRyZB8thBYWAODNYsbhO2XtZthN0/gX+J5Lb7J6MLCq2DIF67PLlNyIAIr65qzeIhr1YHnXNyWvs2JmCSnPsYzMwGlTUIolUNB0S4j8HMbFTyTIBr8CQ5BwYzs0HlGezQ4AERDgxmZoPqN8Gu4QMiHBjMzAbVefGgJcuS24Qs6+5RSWY2vYrMel63sdEn/14cGMxsOvlaDJnclGRm0+nare3XBoHkedZKrFPEgcHMppOvxZDJgcHMppPX3crkwGBm06N1faNDP4OXLGzf3/BhpmVxYDCz6dB5kadnnkruJ2iYaVk8KsnMpkO3zubDz8PilyarsNqvuMZgZtNhkM7mKb+ueKHAIOl4SbdKeiS9X9olzXmS7m65PSfpknTfZyX9sGXf2UXyY2aWKW9ns68rXrjGsAW4LSJOA25Ln7eJiDsi4uyIOBs4HzgE/L+WJJfP74+Iuwvmx8ysu7wXefL8hsKBYT2wI328A7ikT/q3A1+LiEN90pmZlatzfaOszmbPbygcGE6IiAPp4x8DJ/RJvwH4Qse2bZLulXStpOOyXihps6Q5SXMHDx4skGUzm1rrNiYXz3noheS+2wgkz2/oHxgkfV3S/V1u61vTRXIpuMzLwUlaCfwOcEvL5iuA04HfBY4HPpz1+ojYHhEzETGzYsWKftk2MxuOryvef7hqRFyQtU/Sv0laGREH0hP/kz3e6h3AlyPi+Zb3nq9t/ELSZ4D/nDPfZmblal1p9TePh0W/Bs8+PZXXFS/alDQLbEofbwK+0iPtpXQ0I6XBBEki6Z+4v2B+zMwG123y23M/h49+PrvJaYIVDQzXAG+W9AhwQfocSTOSrp9PJGkNcArwzY7X75R0H3AfsBz464L5MTMbnEcitSk08zkingLe1GX7HPDHLc9/BJzUJd35RT7fzKwUHonUxjOfzcw8EqmNA4OZWZUjkRqw3IYX0TMzm+9cHvb6z3k15HKiSqYfNMvMzEzMzc2NOxtmZoM5f00SDDqduDoZ/TRiku6KiJl+6dyUZGZWlYZ0cjswmJlVpSGd3A4MZmZlyNOp3JDlNhwYzMyK6nYNh8vfBaerPUjkXeF1zNz5bGZWVFan8rxFi2sRANz5bGZWlX6dxw1bXsOBwcysqDydxzUbedSLA4OZWVHdOpU71WzkUS8ODGZmRbV2KkPSsdyqhiOPenFgMDMrw/xlQ/8lkus41HzkUS9eK8nMrGzrNjYqEHRyjcHMzNo4MJiZWRsHBjMza+PAYGZmbRwYzMysTSPXSpJ0EOixMElPy4GflJidJvAxT4dpPGaYzuMe9phXR8SKfokaGRiKkDSXZxGpSeJjng7TeMwwncc96mN2U5KZmbVxYDAzszbTGBi2jzsDY+Bjng7TeMwwncc90mOeuj4GMzPrbRprDGZm1sPEBgZJF0p6WNIeSVu67D9O0hfT/d+VtKb6XJYrxzF/SNKDku6VdJuk1ePIZ5n6HXNLuj+QFJIaP3olzzFLekf6v35A0v+sOo9ly/HdXiXpDknfT7/fF40jn2WSdIOkJyXdn7Ffkv4h/ZvcK+nVpX14REzcDVgA/AB4GbAQuAc4syPNnwLXpY83AF8cd74rOObzgMXp4/dPwzGn6X4d+BawG5gZd74r+D+fBnwfWJo+/61x57uCY94OvD99fCbwo3Hnu4Tj/j3g1cD9GfsvAr4GCHgt8N2yPntSawznAnsiYm9E/BK4CVjfkWY9sCN9/CXgTVLn1TUape8xR8QdEXEofbobOLniPJYtz/8Z4Grgb4HnqszciOQ55v8AfCIifgoQEU9WnMey5TnmAH4jffybwBMV5m8kIuJbwNM9kqwHPheJ3cASSSvL+OxJDQwnAY+3PN+XbuuaJiIOA88CyyrJ3WjkOeZW7yMpbTRZ32NOq9enRMT/rTJjI5Tn//zbwG9L+rak3ZIurCx3o5HnmP8KeKekfcBXgT+vJmtjNehvPjdfqGcKSXonMAO8Ydx5GSVJxwD/HXjPmLNStWNJmpPeSFIr/Jak34mIZ8aaq9G6FPhsRPydpNcBn5f0qoh4YdwZa6JJrTHsB05peX5yuq1rGknHklQ/n6okd6OR55iRdAGwFbg4In5RUd5Gpd8x/zrwKuAbkn5E0g472/AO6Dz/533AbEQ8HxE/BP6VJFA0VZ5jfh9wM0BEfAdYRLKe0CTL9ZsfxqQGhjuB0ySdKmkhSefybEeaWWBT+vjtwO2R9ug0VN9jlnQO8GmSoND0dmfoc8wR8WxELI+INRGxhqRf5eKImBtPdkuR57v9zyS1BSQtJ2la2ltlJkuW55gfA94EIOkMksBwsNJcVm8WeHc6Oum1wLMRcaCMN57IpqSIOCzpA8AtJCMaboiIByRdBcxFxCzwjyTVzT0kHTwbxpfj4nIe88eAlwL/lPazPxYRF48t0wXlPOaJkvOYbwHeIulB4AhweUQ0tjac85j/E/A/JF1G0hH9noYX9JD0BZIAvzztO7kSeAlARFxH0pdyEbAHOAS8t7TPbvjfzszMSjapTUlmZjYkBwYzM2vjwGBmZm0cGMzMrI0Dg5mZtXFgMDOzNg4MZmbWxoHBzMza/H/24mGn7HGbjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data['x_tr'], data['y_tr'], 'o', color = red)\n",
    "model = sm.OLS(data[['x_tr']], data[['y_tr']])\n",
    "model = model.fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ec89b5939e8>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data['x_te'], data['y_te'], 'o', color = blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the maximum value of `y` in the training set and in the test set? Please store these variables as `max_y_train` and `max_y_test` below and run the first grader cell! \n",
    "\n",
    "If you get 1 point, it means that you got both right. If you receive 0.5 points, you had only one right, and if you receive 0.25 points, then you correctly entered a tuple but both values were incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe['column_name'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_y_train = data['y_tr'].max()\n",
    "max_y_test = data['y_te'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95500282089616 0.8655959436070828\n"
     ]
    }
   ],
   "source": [
    "# View the results here before you submit\n",
    "print(max_y_train, max_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.0/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_y_train_test', answer = (max_y_train, max_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, comment on the plot differences below. Please record your response into the multiline string named `plot_diffs_string` and then submit it to us via the grader cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diffs_string = '''\n",
    "The training set has more spread out data points than the test set with a much higher max value of 0.96 compared to 0.87 if rounded to 2 decimal points.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_plot_diff_test', answer = plot_diffs_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3. \n",
    "Generate the necessary features to fit polynomial regressions up to the 20th degree (up to and including the $x_{20}$ term) on the training data. Hint: You will be fitting multi-variate linear regression models with polynomial features of $x$. Familiarize yourself with `sklearn.preprocessing.PolynomialFeatures`. \n",
    "\n",
    "Here, we're just asking you to practice generating the features. You'll pass one of them into the autograder for a quick check (although the autograder will not be very strict, so if you end up failing the next test case definitely make sure your work here is correct!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[['x_tr']]\n",
    "poly = PolynomialFeatures(degree=20)\n",
    "x_train = poly.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check to make sure your highest-degree polynomial features are correct; namely the set of features that includes $x_{20}$, or `PolynomialFeatures(degree = 20)`. Please set `polynomial_features_df` as this **dataframe**.\n",
    "\n",
    "If you do not receive full points, that means that either you have the wrong number of columns or some column values aren't correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.249973</td>\n",
       "      <td>0.062486</td>\n",
       "      <td>0.015620</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>2.439818e-04</td>\n",
       "      <td>6.098884e-05</td>\n",
       "      <td>1.524556e-05</td>\n",
       "      <td>3.810976e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.381343e-07</td>\n",
       "      <td>5.952713e-08</td>\n",
       "      <td>1.488017e-08</td>\n",
       "      <td>3.719639e-09</td>\n",
       "      <td>9.298089e-10</td>\n",
       "      <td>2.324270e-10</td>\n",
       "      <td>5.810045e-11</td>\n",
       "      <td>1.452354e-11</td>\n",
       "      <td>3.630491e-12</td>\n",
       "      <td>9.075243e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.073364</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.559195e-07</td>\n",
       "      <td>1.143889e-08</td>\n",
       "      <td>8.392034e-10</td>\n",
       "      <td>6.156737e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>3.313732e-13</td>\n",
       "      <td>2.431089e-14</td>\n",
       "      <td>1.783546e-15</td>\n",
       "      <td>1.308482e-16</td>\n",
       "      <td>9.599553e-18</td>\n",
       "      <td>7.042623e-19</td>\n",
       "      <td>5.166754e-20</td>\n",
       "      <td>3.790541e-21</td>\n",
       "      <td>2.780895e-22</td>\n",
       "      <td>2.040178e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663146</td>\n",
       "      <td>0.439763</td>\n",
       "      <td>0.291627</td>\n",
       "      <td>0.193391</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>8.504639e-02</td>\n",
       "      <td>5.639820e-02</td>\n",
       "      <td>3.740025e-02</td>\n",
       "      <td>2.480184e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090693e-02</td>\n",
       "      <td>7.232889e-03</td>\n",
       "      <td>4.796463e-03</td>\n",
       "      <td>3.180757e-03</td>\n",
       "      <td>2.109307e-03</td>\n",
       "      <td>1.398779e-03</td>\n",
       "      <td>9.275950e-04</td>\n",
       "      <td>6.151311e-04</td>\n",
       "      <td>4.079219e-04</td>\n",
       "      <td>2.705119e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.595366</td>\n",
       "      <td>0.354461</td>\n",
       "      <td>0.211034</td>\n",
       "      <td>0.125643</td>\n",
       "      <td>0.074803</td>\n",
       "      <td>4.453545e-02</td>\n",
       "      <td>2.651491e-02</td>\n",
       "      <td>1.578608e-02</td>\n",
       "      <td>9.398503e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>3.331404e-03</td>\n",
       "      <td>1.983406e-03</td>\n",
       "      <td>1.180853e-03</td>\n",
       "      <td>7.030403e-04</td>\n",
       "      <td>4.185665e-04</td>\n",
       "      <td>2.492004e-04</td>\n",
       "      <td>1.483656e-04</td>\n",
       "      <td>8.833186e-05</td>\n",
       "      <td>5.258982e-05</td>\n",
       "      <td>3.131021e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.415146</td>\n",
       "      <td>0.172346</td>\n",
       "      <td>0.071549</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>5.119210e-03</td>\n",
       "      <td>2.125218e-03</td>\n",
       "      <td>8.822750e-04</td>\n",
       "      <td>3.662726e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312559e-05</td>\n",
       "      <td>2.620631e-05</td>\n",
       "      <td>1.087944e-05</td>\n",
       "      <td>4.516551e-06</td>\n",
       "      <td>1.875027e-06</td>\n",
       "      <td>7.784092e-07</td>\n",
       "      <td>3.231532e-07</td>\n",
       "      <td>1.341556e-07</td>\n",
       "      <td>5.569413e-08</td>\n",
       "      <td>2.312118e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.320401</td>\n",
       "      <td>0.102657</td>\n",
       "      <td>0.032891</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>1.081846e-03</td>\n",
       "      <td>3.466249e-04</td>\n",
       "      <td>1.110591e-04</td>\n",
       "      <td>3.558347e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.652891e-06</td>\n",
       "      <td>1.170391e-06</td>\n",
       "      <td>3.749948e-07</td>\n",
       "      <td>1.201488e-07</td>\n",
       "      <td>3.849584e-08</td>\n",
       "      <td>1.233412e-08</td>\n",
       "      <td>3.951866e-09</td>\n",
       "      <td>1.266183e-09</td>\n",
       "      <td>4.056867e-10</td>\n",
       "      <td>1.299825e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.164287</td>\n",
       "      <td>0.026990</td>\n",
       "      <td>0.004434</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>1.966150e-05</td>\n",
       "      <td>3.230126e-06</td>\n",
       "      <td>5.306672e-07</td>\n",
       "      <td>8.718165e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>2.353047e-09</td>\n",
       "      <td>3.865747e-10</td>\n",
       "      <td>6.350914e-11</td>\n",
       "      <td>1.043372e-11</td>\n",
       "      <td>1.714122e-12</td>\n",
       "      <td>2.816077e-13</td>\n",
       "      <td>4.626444e-14</td>\n",
       "      <td>7.600639e-15</td>\n",
       "      <td>1.248685e-15</td>\n",
       "      <td>2.051425e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783161</td>\n",
       "      <td>0.613342</td>\n",
       "      <td>0.480346</td>\n",
       "      <td>0.376188</td>\n",
       "      <td>0.294616</td>\n",
       "      <td>2.307320e-01</td>\n",
       "      <td>1.807004e-01</td>\n",
       "      <td>1.415176e-01</td>\n",
       "      <td>1.108311e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.797735e-02</td>\n",
       "      <td>5.323724e-02</td>\n",
       "      <td>4.169335e-02</td>\n",
       "      <td>3.265262e-02</td>\n",
       "      <td>2.557228e-02</td>\n",
       "      <td>2.002722e-02</td>\n",
       "      <td>1.568455e-02</td>\n",
       "      <td>1.228353e-02</td>\n",
       "      <td>9.619988e-03</td>\n",
       "      <td>7.534004e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>0.015006</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>3.378867e-06</td>\n",
       "      <td>4.139039e-07</td>\n",
       "      <td>5.070235e-08</td>\n",
       "      <td>6.210929e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>9.319950e-11</td>\n",
       "      <td>1.141674e-11</td>\n",
       "      <td>1.398526e-12</td>\n",
       "      <td>1.713165e-13</td>\n",
       "      <td>2.098590e-14</td>\n",
       "      <td>2.570728e-15</td>\n",
       "      <td>3.149087e-16</td>\n",
       "      <td>3.857564e-17</td>\n",
       "      <td>4.725434e-18</td>\n",
       "      <td>5.788555e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634907</td>\n",
       "      <td>0.403106</td>\n",
       "      <td>0.255935</td>\n",
       "      <td>0.162495</td>\n",
       "      <td>0.103169</td>\n",
       "      <td>6.550271e-02</td>\n",
       "      <td>4.158811e-02</td>\n",
       "      <td>2.640457e-02</td>\n",
       "      <td>1.676444e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>6.757852e-03</td>\n",
       "      <td>4.290606e-03</td>\n",
       "      <td>2.724134e-03</td>\n",
       "      <td>1.729571e-03</td>\n",
       "      <td>1.098116e-03</td>\n",
       "      <td>6.972012e-04</td>\n",
       "      <td>4.426577e-04</td>\n",
       "      <td>2.810463e-04</td>\n",
       "      <td>1.784382e-04</td>\n",
       "      <td>1.132916e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5             6   \\\n",
       "0   1.0  0.249973  0.062486  0.015620  0.003905  0.000976  2.439818e-04   \n",
       "1   1.0  0.073364  0.005382  0.000395  0.000029  0.000002  1.559195e-07   \n",
       "2   1.0  0.663146  0.439763  0.291627  0.193391  0.128247  8.504639e-02   \n",
       "3   1.0  0.595366  0.354461  0.211034  0.125643  0.074803  4.453545e-02   \n",
       "4   1.0  0.415146  0.172346  0.071549  0.029703  0.012331  5.119210e-03   \n",
       "..  ...       ...       ...       ...       ...       ...           ...   \n",
       "95  1.0  0.320401  0.102657  0.032891  0.010538  0.003377  1.081846e-03   \n",
       "96  1.0  0.164287  0.026990  0.004434  0.000728  0.000120  1.966150e-05   \n",
       "97  1.0  0.783161  0.613342  0.480346  0.376188  0.294616  2.307320e-01   \n",
       "98  1.0  0.122498  0.015006  0.001838  0.000225  0.000028  3.378867e-06   \n",
       "99  1.0  0.634907  0.403106  0.255935  0.162495  0.103169  6.550271e-02   \n",
       "\n",
       "              7             8             9   ...            11            12  \\\n",
       "0   6.098884e-05  1.524556e-05  3.810976e-06  ...  2.381343e-07  5.952713e-08   \n",
       "1   1.143889e-08  8.392034e-10  6.156737e-11  ...  3.313732e-13  2.431089e-14   \n",
       "2   5.639820e-02  3.740025e-02  2.480184e-02  ...  1.090693e-02  7.232889e-03   \n",
       "3   2.651491e-02  1.578608e-02  9.398503e-03  ...  3.331404e-03  1.983406e-03   \n",
       "4   2.125218e-03  8.822750e-04  3.662726e-04  ...  6.312559e-05  2.620631e-05   \n",
       "..           ...           ...           ...  ...           ...           ...   \n",
       "95  3.466249e-04  1.110591e-04  3.558347e-05  ...  3.652891e-06  1.170391e-06   \n",
       "96  3.230126e-06  5.306672e-07  8.718165e-08  ...  2.353047e-09  3.865747e-10   \n",
       "97  1.807004e-01  1.415176e-01  1.108311e-01  ...  6.797735e-02  5.323724e-02   \n",
       "98  4.139039e-07  5.070235e-08  6.210929e-09  ...  9.319950e-11  1.141674e-11   \n",
       "99  4.158811e-02  2.640457e-02  1.676444e-02  ...  6.757852e-03  4.290606e-03   \n",
       "\n",
       "              13            14            15            16            17  \\\n",
       "0   1.488017e-08  3.719639e-09  9.298089e-10  2.324270e-10  5.810045e-11   \n",
       "1   1.783546e-15  1.308482e-16  9.599553e-18  7.042623e-19  5.166754e-20   \n",
       "2   4.796463e-03  3.180757e-03  2.109307e-03  1.398779e-03  9.275950e-04   \n",
       "3   1.180853e-03  7.030403e-04  4.185665e-04  2.492004e-04  1.483656e-04   \n",
       "4   1.087944e-05  4.516551e-06  1.875027e-06  7.784092e-07  3.231532e-07   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "95  3.749948e-07  1.201488e-07  3.849584e-08  1.233412e-08  3.951866e-09   \n",
       "96  6.350914e-11  1.043372e-11  1.714122e-12  2.816077e-13  4.626444e-14   \n",
       "97  4.169335e-02  3.265262e-02  2.557228e-02  2.002722e-02  1.568455e-02   \n",
       "98  1.398526e-12  1.713165e-13  2.098590e-14  2.570728e-15  3.149087e-16   \n",
       "99  2.724134e-03  1.729571e-03  1.098116e-03  6.972012e-04  4.426577e-04   \n",
       "\n",
       "              18            19            20  \n",
       "0   1.452354e-11  3.630491e-12  9.075243e-13  \n",
       "1   3.790541e-21  2.780895e-22  2.040178e-23  \n",
       "2   6.151311e-04  4.079219e-04  2.705119e-04  \n",
       "3   8.833186e-05  5.258982e-05  3.131021e-05  \n",
       "4   1.341556e-07  5.569413e-08  2.312118e-08  \n",
       "..           ...           ...           ...  \n",
       "95  1.266183e-09  4.056867e-10  1.299825e-10  \n",
       "96  7.600639e-15  1.248685e-15  2.051425e-16  \n",
       "97  1.228353e-02  9.619988e-03  7.534004e-03  \n",
       "98  3.857564e-17  4.725434e-18  5.788555e-19  \n",
       "99  2.810463e-04  1.784382e-04  1.132916e-04  \n",
       "\n",
       "[100 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_features_df = pd.DataFrame(x_train)\n",
    "polynomial_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.0/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_poly_coefficients_setups', answer = polynomial_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A4. \n",
    "Calculate the training MSE and the test MSE for 20 polynomial models up to degree 20. Store these as lists named `mse_train` and `mse_test` respectively. Hint: Familiarize yourself with the `sklearn.metrics.mean_squared_error` package and try to automate the process, e.g., using a for loop with degrees going from 1 to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = []\n",
    "mse_test = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    x_tr = poly.fit_transform(data[['x_tr']])\n",
    "    x_te = poly.fit_transform(data[['x_te']])\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(x_tr, data[['y_tr']])\n",
    "    \n",
    "    y_tr_pred = model.predict(x_tr)\n",
    "    y_te_pred = model.predict(x_te)\n",
    "    \n",
    "    mse_train.append(mean_squared_error(data[['y_tr']], y_tr_pred))\n",
    "    mse_test.append(mean_squared_error(data[['y_te']], y_te_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the grader cells for both `mse_train` and `mse_test` in order; please make sure you don't put the wrong cell in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.5/1.5 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_mse_polynomials_train', answer = mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.5/1.5 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_mse_polynomials_test', answer = mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A5.\n",
    "\n",
    "Generate a plot of both the training MSE and test MSE against flexibility (polynomial degree) for degrees 1 to 20. \n",
    "\n",
    "Find the minimum training and testing MSEs and set them to `min_train_mse` and `min_test_mse` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,21), mse_train, 'o', color=red)\n",
    "plt.plot(range(1,21), mse_test, 'o', color=blue)\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train_mse = min(mse_train)\n",
    "min_test_mse = min(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024833781487058403 0.03234864152603839\n"
     ]
    }
   ],
   "source": [
    "print(min_train_mse, min_test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint*: You should see the `min_train_mse < min_test_mse` since we have a bit of overfitting. Run the grader cell below! Each of the variables is worth 1 point; we assign points based on how close you are to the true answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 2.0/2 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_min_mses_test', answer = (min_train_mse, min_test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A6. \n",
    "From your plot, make an educated guess about the polynomial degree of the function that\n",
    "was used to generate the data. Then, give an estimate of the irreducible error $Var(\\epsilon)$ for the optimal model on both the training set and test set. \n",
    "\n",
    "*Hint*: The optimal model is obtained when we use the maximal degree polynomial that does not overfit. Revisit the section on hypothesis testing and think about the relationship between MSE, RSS, and RSE to calculate the irreducible error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the plot, it looks like the polynomial degree of the function that was used to generate the data is 5.\n",
    "#var = sigma^2, RSE = sigma, MSE = 1/N * RSS,so RSS = MSE * N\n",
    "degree = 5\n",
    "N_train = len(data['x_tr'])\n",
    "N_test = len(data['x_te'])\n",
    "RSS_tr = min_train_mse * N_train\n",
    "RSS_te = min_test_mse * N_test\n",
    "# RSE_train_sq = RSS_tr / (N_train - degree - 1) \n",
    "RSE_train_sq = RSS_tr / (N_train - 20 - 1) \n",
    "RSE_test_sq = RSS_te / (N_test - degree - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please set your respective irreducible errors as `RSE_train_sq` and `RSE_test_sq` respectively, and set the number of polynomial features as `degree`. Then, run the grader cell below. It grades similar to above, but we add 1 point for the `degree` variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired degree for best model:  5\n",
      "Irreducible error (training):  0.03143516643931443\n",
      "Irreducible error (test):  0.034413448431955734\n"
     ]
    }
   ],
   "source": [
    "print(\"Desired degree for best model: \", degree)\n",
    "print(\"Irreducible error (training): \", RSE_train_sq)\n",
    "print(\"Irreducible error (test): \", RSE_test_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 3.0/3 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_irreducible', answer = (degree, RSE_train_sq, RSE_test_sq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "Next, we will use the `Ch3PartB` dataset to observe the effects of collinearity using `statsmodels`.\n",
    "This dataset contains 100 observations of points $(x1, x2)$, and $y$, the response variable.\n",
    "\n",
    "### B1. \n",
    "Load the data from `Ch3PartB.csv` into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.417022</td>\n",
       "      <td>0.240074</td>\n",
       "      <td>2.949735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.720324</td>\n",
       "      <td>0.157942</td>\n",
       "      <td>3.261717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>-0.030563</td>\n",
       "      <td>3.322517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.302333</td>\n",
       "      <td>0.233964</td>\n",
       "      <td>2.387546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.146756</td>\n",
       "      <td>0.096387</td>\n",
       "      <td>3.002498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>0.237027</td>\n",
       "      <td>-0.071123</td>\n",
       "      <td>1.719446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0.903380</td>\n",
       "      <td>0.386998</td>\n",
       "      <td>4.758863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.573679</td>\n",
       "      <td>0.376988</td>\n",
       "      <td>4.803815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.254268</td>\n",
       "      <td>2.840827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>0.617145</td>\n",
       "      <td>0.283709</td>\n",
       "      <td>4.204311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0        x1        x2         y\n",
       "0            0  0.417022  0.240074  2.949735\n",
       "1            1  0.720324  0.157942  3.261717\n",
       "2            2  0.000114 -0.030563  3.322517\n",
       "3            3  0.302333  0.233964  2.387546\n",
       "4            4  0.146756  0.096387  3.002498\n",
       "..         ...       ...       ...       ...\n",
       "95          95  0.237027 -0.071123  1.719446\n",
       "96          96  0.903380  0.386998  4.758863\n",
       "97          97  0.573679  0.376988  4.803815\n",
       "98          98  0.002870  0.254268  2.840827\n",
       "99          99  0.617145  0.283709  4.204311\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataB = pd.read_csv('Ch3PartB.csv')\n",
    "dataB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2. \n",
    "Show a scatterplot displaying the relationship between $x1$ and $x2$ \n",
    "\n",
    "What is the correlation coefficient between $x1$ and $x2$? Compute the answer and store it as `correlation_variable` -- it should be a single floating-point number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ec89b118400>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dataB[['x1']], dataB[['x2']], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8390596222844913\n"
     ]
    }
   ],
   "source": [
    "correlation_variable = np.corrcoef(dataB['x1'], dataB['x2'])[0,1]\n",
    "print(correlation_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 0.5/0.5 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_correlation', answer = correlation_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3. \n",
    "\n",
    "Using the data, fit a least squares regression to predict $y$ using $x1$ and $x2$. Describe your results in a Markdown cell. \n",
    "\n",
    "*Hint*: Familiarize yourself with `statsmodels.formula.api.ols`. \n",
    "\n",
    "We have several questions here as well:\n",
    "\n",
    "(a) What are the estimates $\\hat{\\beta_0}, \\hat{\\beta_1}, \\hat{\\beta_2}$?\n",
    "\n",
    "(b) At a 95% confidence level, can you reject the null hypothesis $H_0: \\beta_1 = 0$? \n",
    "\n",
    "(c) What about $H_0: \\beta_2 = 0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   17.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Sep 2024</td> <th>  Prob (F-statistic):</th> <td>4.40e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:11:14</td>     <th>  Log-Likelihood:    </th> <td> -142.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   290.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   298.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.1893</td> <td>    0.199</td> <td>   11.021</td> <td> 0.000</td> <td>    1.795</td> <td>    2.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>    0.7046</td> <td>    0.637</td> <td>    1.107</td> <td> 0.271</td> <td>   -0.559</td> <td>    1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>    2.5024</td> <td>    1.140</td> <td>    2.194</td> <td> 0.031</td> <td>    0.239</td> <td>    4.766</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.607</td> <th>  Durbin-Watson:     </th> <td>   2.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.738</td> <th>  Jarque-Bera (JB):  </th> <td>   0.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.179</td> <th>  Prob(JB):          </th> <td>   0.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.900</td> <th>  Cond. No.          </th> <td>    14.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.261\n",
       "Model:                            OLS   Adj. R-squared:                  0.245\n",
       "Method:                 Least Squares   F-statistic:                     17.09\n",
       "Date:                Sat, 21 Sep 2024   Prob (F-statistic):           4.40e-07\n",
       "Time:                        17:11:14   Log-Likelihood:                -142.34\n",
       "No. Observations:                 100   AIC:                             290.7\n",
       "Df Residuals:                      97   BIC:                             298.5\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.1893      0.199     11.021      0.000       1.795       2.584\n",
       "x1             0.7046      0.637      1.107      0.271      -0.559       1.968\n",
       "x2             2.5024      1.140      2.194      0.031       0.239       4.766\n",
       "==============================================================================\n",
       "Omnibus:                        0.607   Durbin-Watson:                   2.111\n",
       "Prob(Omnibus):                  0.738   Jarque-Bera (JB):                0.577\n",
       "Skew:                          -0.179   Prob(JB):                        0.749\n",
       "Kurtosis:                       2.900   Cond. No.                         14.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.ols('y~x1+x2',data=dataB).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your answers to $\\hat{\\beta_0}, \\hat{\\beta_1}, \\hat{\\beta_2}$, please input them either using code or typing the numbers from `statsmodels`' output into the variables below. You should include at least 4 digits after the decimal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0 = 2.1893\n",
    "beta_1 = 0.7046\n",
    "beta_2 = 2.5024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run but *do not change* the cell below to set up your autograder. Afterr, run the first grader cell with these variables! You will receive 0.5 points for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CELL!\n",
    "answer_dict = {\n",
    "    0: beta_0, \n",
    "    1: beta_1,\n",
    "    2: beta_2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.5/1.5 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_betas', answer = answer_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to evaluate the hypothesis test of $H_0: \\beta_1 = 0$ when both $x1$ and $x2$ are present.\n",
    "\n",
    "Please compute either the $t$-value or $p$-value and set it as `test_statistic_b1`, then determine whether or not you reject the null hypothesiss at the $95\\%$ confidence level. Set that variable as a boolean (`True/False`) as `reject_null_b1`. \n",
    "\n",
    "If your values are either incorrect or do not agree (i.e. you said the null would be rejected when it should not be), then you will not receive full points!\n",
    "\n",
    "You will receive 0.5 points for getting the correct statistics as well as 1 points for your in-context evaluation of the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    8.532403e-19\n",
       "x1           2.712146e-01\n",
       "x2           3.060418e-02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistic_b1 = .2712 # use t or p, to at least 3 significant digits\n",
    "reject_null_b1 = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.5/1.5 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_beta1_hypothesis', answer = (test_statistic_b1, reject_null_b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for the other test, to evaluate the hypothesis test of $H_0: \\beta_2 = 0$  when both $x1$ and $x2$ are present.\n",
    "\n",
    "Please compute either the $t$-value or $p$-value and set it as `test_statistic_b2`, then determine whether or not you reject the null hypothesiss at the $95\\%$ confidence level. Set that variable as a boolean (`True/False`) as `reject_null_b2`\n",
    "\n",
    "You will receive 0.5 points for getting the correct statistics as well as 1 point for your in-context evaluation of the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistic_b2 = 0.030604 # use t or p, to at least 3 significant digits\n",
    "reject_null_b2 = True #0.05 > 0.030\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.5/1.5 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_beta2_hypothesis', answer = (test_statistic_b2, reject_null_b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4. \n",
    "\n",
    "Now fit a least squares regression to predict $y$ using only $x1$. Comment on your results.\n",
    "\n",
    "Can you reject the null hypothesis $H_0: \\beta_1 = 0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   28.26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Sep 2024</td> <th>  Prob (F-statistic):</th> <td>6.68e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:11:25</td>     <th>  Log-Likelihood:    </th> <td> -144.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   293.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   298.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.2486</td> <td>    0.201</td> <td>   11.209</td> <td> 0.000</td> <td>    1.850</td> <td>    2.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>    1.8770</td> <td>    0.353</td> <td>    5.316</td> <td> 0.000</td> <td>    1.176</td> <td>    2.578</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.292</td> <th>  Durbin-Watson:     </th> <td>   2.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.864</td> <th>  Jarque-Bera (JB):  </th> <td>   0.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.003</td> <th>  Prob(JB):          </th> <td>   0.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.665</td> <th>  Cond. No.          </th> <td>    4.26</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.224\n",
       "Model:                            OLS   Adj. R-squared:                  0.216\n",
       "Method:                 Least Squares   F-statistic:                     28.26\n",
       "Date:                Sat, 21 Sep 2024   Prob (F-statistic):           6.68e-07\n",
       "Time:                        17:11:25   Log-Likelihood:                -144.76\n",
       "No. Observations:                 100   AIC:                             293.5\n",
       "Df Residuals:                      98   BIC:                             298.7\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.2486      0.201     11.209      0.000       1.850       2.647\n",
       "x1             1.8770      0.353      5.316      0.000       1.176       2.578\n",
       "==============================================================================\n",
       "Omnibus:                        0.292   Durbin-Watson:                   2.123\n",
       "Prob(Omnibus):                  0.864   Jarque-Bera (JB):                0.468\n",
       "Skew:                          -0.003   Prob(JB):                        0.791\n",
       "Kurtosis:                       2.665   Cond. No.                         4.26\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = smf.ols('y~x1', data=dataB).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating $H_0: \\beta_1 = 0$ when fitting with only $x1$ please do the following:\n",
    "\n",
    "- Please compute either the $t$-value or $p$-value and set it as `test_statistic_b4`\n",
    "- Determine whether or not you reject the null hypothesiss at the $95\\%$ confidence level; set that variable as a boolean (`True/False`) as `reject_null_b4`\n",
    "- Determine if $x1$ is significant; set that result as a boolean (`True/False`) as `is_x1_significant`\n",
    "\n",
    "Similar to previously, you'll receive points both for your test statistics and the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    11.209167\n",
       "x1            5.315681\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistic_b4 = 5.3156 # use t or p, to at least 3 significant digits\n",
    "#t-statistic of 2 or higher is statistically significant, we can reject null hypothesis\n",
    "reject_b4_null_hypothesis = True\n",
    "is_x1_significant = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.5/1.5 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_b4_x1_hypothesis', answer = (\n",
    "    test_statistic_b4, \n",
    "    reject_b4_null_hypothesis, \n",
    "    is_x1_significant)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B5. \n",
    "\n",
    "Now fit a least squares regression to predict $y$ using only $x2$. Comment on your results.\n",
    "\n",
    "Can you reject the null hypothesis $H_0: \\beta_2 = 0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   32.87</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Sep 2024</td> <th>  Prob (F-statistic):</th> <td>1.09e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:11:30</td>     <th>  Log-Likelihood:    </th> <td> -142.97</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   289.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   295.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.2655</td> <td>    0.187</td> <td>   12.145</td> <td> 0.000</td> <td>    1.895</td> <td>    2.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>    3.5613</td> <td>    0.621</td> <td>    5.733</td> <td> 0.000</td> <td>    2.329</td> <td>    4.794</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.857</td> <th>  Durbin-Watson:     </th> <td>   2.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.651</td> <th>  Jarque-Bera (JB):  </th> <td>   0.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.210</td> <th>  Prob(JB):          </th> <td>   0.689</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.946</td> <th>  Cond. No.          </th> <td>    6.48</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.251\n",
       "Model:                            OLS   Adj. R-squared:                  0.244\n",
       "Method:                 Least Squares   F-statistic:                     32.87\n",
       "Date:                Sat, 21 Sep 2024   Prob (F-statistic):           1.09e-07\n",
       "Time:                        17:11:30   Log-Likelihood:                -142.97\n",
       "No. Observations:                 100   AIC:                             289.9\n",
       "Df Residuals:                      98   BIC:                             295.1\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.2655      0.187     12.145      0.000       1.895       2.636\n",
       "x2             3.5613      0.621      5.733      0.000       2.329       4.794\n",
       "==============================================================================\n",
       "Omnibus:                        0.857   Durbin-Watson:                   2.117\n",
       "Prob(Omnibus):                  0.651   Jarque-Bera (JB):                0.746\n",
       "Skew:                          -0.210   Prob(JB):                        0.689\n",
       "Kurtosis:                       2.946   Cond. No.                         6.48\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = smf.ols('y~x2', data=dataB).fit()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating $H_0: \\beta_2 = 0$ when fitting with only $x1$ please do the following:\n",
    "\n",
    "- Please compute either the $t$-value or $p$-value and set it as `test_statistic_b5`\n",
    "- Determine whether or not you reject the null hypothesiss at the $95\\%$ confidence level; set that variable as a boolean (`True/False`) as `reject_null_b5`\n",
    "- Determine if $x2$ is significant; set that result as a boolean (`True/False`) as `is_x2_significant`\n",
    "\n",
    "Scoring is identical to B4 above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    12.145167\n",
       "x2            5.733353\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistic_b5 = 5.7333 # use t or p, to at least 3 significant digits\n",
    "#THe t-statisic is again bigger than 2 so it is significant.\n",
    "reject_b5_null_hypothesis = True\n",
    "is_x2_significant = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1.5/1.5 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_b5_x2_hypothesis', answer = (\n",
    "    test_statistic_b5, \n",
    "    reject_b5_null_hypothesis, \n",
    "    is_x2_significant)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B6. \n",
    "\n",
    "Do Part B Questions 3-5 contradict each other? Explain why or why not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The questions seem to contradict each other because beta_1 in the multiple regression was not significant. However, because of collinearity, these 2 predicters were closely related causing this reading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, comment on the apparent contradiction below. Enter a boolean (`True/False`) for whether or not the answers contradict as `is_contradiction`, and then record your explanation into the multiline string named `contradiction_string` and then submit it to us via the grader cell!\n",
    "\n",
    "Please note that you'll need to have the right answer as well as have an explanation that has a reasonable set of keywords in order to get full credit!\n",
    "\n",
    "*Note*: if you have an explanation that you think is reasonable but you aren't passing the autograder, let us know on Piazza!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_contradiction = False\n",
    "contradiction_string = '''\n",
    "The questions seem to contradict each other because beta_1 in the multiple regression was not significant. However, this is false because of collinearity, these 2 predicters were closely related causing the variables to lose there statistical significance.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! You earned 1/1 points. You are a star!\n",
      "\n",
      "Your submission has been successfully recorded in the gradebook.\n"
     ]
    }
   ],
   "source": [
    "grader.grade(test_case_id = 'test_contradiction_test', answer = (is_contradiction, contradiction_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit\n",
    "\n",
    "You're done! Please make sure you've run all the PennGrader cells and count up your score to be sure (there are 20 points in total) and then make sure to submit this on Codio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
